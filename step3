#!/bin/csh -f
#=============================================================================
# Dial3_consol: Consolidates all data files to a common load area. 
#               Trap duplicate ENTSID's
#
# 12/15/97 (AJC) - Originally (Step #6/Step #7) of chkdial.csh created 8/11/97
#                - Revised 02/13/98
# 06/15/2015 (IM) - Added functionality to support MODELS data file
#=============================================================================
set nonomatch
source DIAL.path
#=============================================================================
#  Step #3 - (Global) Consolidate all data files to a common load area
#  c.inDIAL - 07/22/97 (annbro) Original Program Version 
#=============================================================================
echo "--- Step #3 - Consolidate all data files to a common load area ---" >> $CONSOLDIR/diallog
date >> $CONSOLDIR/diallog
#
cd $CONSOLDIR
/bin/rm DIAL*.dat MODELS.dat *.ctl *.log *.bad errlog >& /dev/null
foreach place ($dbpath)
	unsetenv DBPATH 
	setenv DBPATH $ALSDIR/$place
	setenv DIALDIR $ALSDIR/$place/DIALDIR
	cd $DIALDIR
	ls CFF??ent.???? >> $CONSOLDIR/dialload.log
	ls QUEUE??ent.???? >> $CONSOLDIR/dialload.log
	ls CFF??mod.???? >> $CONSOLDIR/dialload.log
	ls QUEUE??mod.???? >> $CONSOLDIR/dialload.log
        ls MODELS??.???? >> $CONSOLDIR/dialload.log
        cat CFF??ent.???? >> $CONSOLDIR/DIALENT.dat
	cat QUEUE??ent.???? >> $CONSOLDIR/DIALENT.dat
	cat CFF??mod.???? >> $CONSOLDIR/DIALMOD.dat 
	cat QUEUE??mod.???? >> $CONSOLDIR/DIALMOD.dat
	cat CFF??sum.???? >> $CONSOLDIR/DIALSUM.dat
	cat QUEUE??sum.???? >> $CONSOLDIR/DIALSUM.dat
        cat MODELS??.???? >> $CONSOLDIR/MODELS.dat
end
echo "Data consolidated to DIALENT.dat, DIALMOD.dat, DIALSUM.dat and MODELS.dat" >> $CONSOLDIR/diallog
date >> $CONSOLDIR/diallog
echo "--- Consolidation of data files Completed ------------------------" >> $CONSOLDIR/diallog
#=============================================================================
#  Step #3 - TRAP DUPLICATE ENTSID'S (AJC) 8/15/97
#=============================================================================
echo "--- Step #3 - Trap duplicated ENTSID's ------" >> $CONSOLDIR/diallog
date >> $CONSOLDIR/diallog
#
cd $CONSOLDIR
cut -d \| -f1 DIALENT.dat | sort | uniq -d > dupENTSID
if ( ! -z dupENTSID) then 
	echo "`date +%m/%d/%Y` - Step #3 - PROBLEM: Duplicate ENTSID'S" >> $CONSOLDIR/diallog
else
	echo "No duplicated ENTSID's found" >> $CONSOLDIR/diallog
endif
#=============================================================================
cd $DIAL
#
date >> $CONSOLDIR/diallog
echo "--- Trap duplicated ENTSID's Completed ------" >> $CONSOLDIR/diallog

////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
import java.io.*;
import java.nio.file.*;
import java.util.*;
import java.util.stream.*;

public class Consolidator {
    static String CONSOLDIR = "/path/to/consoldir";
    static List<String> dbpaths = Arrays.asList("db1", "db2"); // Example list; replace with actual paths
    static String ALSDIR = "/path/to/alsdir"; // Base directory
    static String DIAL = "/path/to/dial";

    public static void main(String[] args) throws IOException {
        log("--- Step #3 - Consolidate all data files to a common load area ---");

        // Step 1: Clear existing consolidated files
        Files.createDirectories(Paths.get(CONSOLDIR));
        clearFiles(CONSOLDIR, Arrays.asList("DIAL*.dat", "MODELS.dat", "*.ctl", "*.log", "*.bad", "errlog"));

        // Consolidate files
        try (
            BufferedWriter entWriter = new BufferedWriter(new FileWriter(CONSOLDIR + "/DIALENT.dat", true));
            BufferedWriter modWriter = new BufferedWriter(new FileWriter(CONSOLDIR + "/DIALMOD.dat", true));
            BufferedWriter sumWriter = new BufferedWriter(new FileWriter(CONSOLDIR + "/DIALSUM.dat", true));
            BufferedWriter modelsWriter = new BufferedWriter(new FileWriter(CONSOLDIR + "/MODELS.dat", true));
            BufferedWriter logWriter = new BufferedWriter(new FileWriter(CONSOLDIR + "/dialload.log", true))
        ) {
            for (String place : dbpaths) {
                Path DIALDIR = Paths.get(ALSDIR, place, "DIALDIR");
                if (!Files.isDirectory(DIALDIR)) continue;

                logWriter.write("Processing: " + DIALDIR.toString() + "\n");

                concatFiles(DIALDIR, "CFF??ent.????", entWriter, logWriter);
                concatFiles(DIALDIR, "QUEUE??ent.????", entWriter, logWriter);
                concatFiles(DIALDIR, "CFF??mod.????", modWriter, logWriter);
                concatFiles(DIALDIR, "QUEUE??mod.????", modWriter, logWriter);
                concatFiles(DIALDIR, "CFF??sum.????", sumWriter, logWriter);
                concatFiles(DIALDIR, "QUEUE??sum.????", sumWriter, logWriter);
                concatFiles(DIALDIR, "MODELS??.????", modelsWriter, logWriter);
            }
        }

        log("Data consolidated to DIALENT.dat, DIALMOD.dat, DIALSUM.dat and MODELS.dat");
        log("--- Consolidation of data files Completed ------------------------");

        // Trap duplicate ENTSIDs
        log("--- Step #3 - Trap duplicated ENTSID's ------");

        Path dialentPath = Paths.get(CONSOLDIR, "DIALENT.dat");
        List<String> entsids = Files.lines(dialentPath)
                                    .map(line -> line.split("\\|")[0])
                                    .collect(Collectors.toList());

        Map<String, Long> duplicates = entsids.stream()
                                              .collect(Collectors.groupingBy(s -> s, Collectors.counting()))
                                              .entrySet().stream()
                                              .filter(e -> e.getValue() > 1)
                                              .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));

        Path dupFile = Paths.get(CONSOLDIR, "dupENTSID");
        Files.write(dupFile, duplicates.keySet());

        if (!duplicates.isEmpty()) {
            log(currentDate() + " - Step #3 - PROBLEM: Duplicate ENTSID'S");
        } else {
            log("No duplicated ENTSID's found");
        }

        log("--- Trap duplicated ENTSID's Completed ------");
    }

    private static void clearFiles(String dir, List<String> patterns) throws IOException {
        for (String pattern : patterns) {
            try (DirectoryStream<Path> stream = Files.newDirectoryStream(Paths.get(dir), pattern)) {
                for (Path entry : stream) {
                    Files.deleteIfExists(entry);
                }
            } catch (IOException ignored) {
            }
        }
    }

    private static void concatFiles(Path dir, String glob, BufferedWriter out, BufferedWriter logWriter) throws IOException {
        try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir, glob)) {
            for (Path file : stream) {
                logWriter.write("Adding: " + file.getFileName() + "\n");
                Files.lines(file).forEach(line -> {
                    try {
                        out.write(line);
                        out.newLine();
                    } catch (IOException e) {
                        e.printStackTrace();
                    }
                });
            }
        } catch (IOException ignored) {
        }
    }

    private static void log(String message) throws IOException {
        String timestamp = currentDate();
        try (BufferedWriter writer = new BufferedWriter(new FileWriter(CONSOLDIR + "/diallog", true))) {
            writer.write(timestamp + " - " + message + "\n");
        }
    }

    private static String currentDate() {
        return java.time.LocalDateTime.now().toString();
    }
}


///////////////////////////////////////////////////////////////////////


import java.sql.*;

public class OracleIndexDropper {

    public static void dropIndexIfExists(Connection conn, String indexName, String schema) throws SQLException {
        String checkSql = "SELECT COUNT(*) FROM ALL_INDEXES WHERE INDEX_NAME = ? AND OWNER = ?";
        String dropSql = "DROP INDEX " + schema + "." + indexName;

        try (
            PreparedStatement checkStmt = conn.prepareStatement(checkSql)
        ) {
            checkStmt.setString(1, indexName.toUpperCase());
            checkStmt.setString(2, schema.toUpperCase());

            ResultSet rs = checkStmt.executeQuery();
            if (rs.next() && rs.getInt(1) > 0) {
                try (Statement dropStmt = conn.createStatement()) {
                    dropStmt.executeUpdate(dropSql);
                    System.out.println("Index dropped: " + schema + "." + indexName);
                } catch (SQLException e) {
                    System.err.println("Failed to drop index: " + e.getMessage());
                    throw e;
                }
            } else {
                System.out.println("Index does not exist: " + schema + "." + indexName);
            }
        }
    }
}

\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\
try (Connection conn = DriverManager.getConnection(DB_URL, USER, PASSWORD)) {
    OracleIndexDropper.dropIndexIfExists(conn, "IDX_EMP_NAME", "HR");
} catch (SQLException e) {
    e.printStackTrace();
}

/////////////////////////////////////////////////

try {
    jdbcTemplate.execute("ALTER TABLE ... ADD CONSTRAINT ...");
} catch (DataAccessException e) {
    if (e.getMessage().contains("ORA-00955") || e.getMessage().contains("ORA-02275")) {
        System.out.println("Constraint already exists. Skipping.");
    } else {
        throw e;
    }
}


////////////////////////////////////////////////////////

import org.springframework.jdbc.core.JdbcTemplate;

import java.sql.Connection;
import java.sql.SQLException;
import java.sql.Statement;

public class ConstraintBatchProcessor {

    private final JdbcTemplate jdbcTemplate;

    public ConstraintBatchProcessor(JdbcTemplate jdbcTemplate) {
        this.jdbcTemplate = jdbcTemplate;
    }

    public void processConstraintsBatch() throws SQLException {
        try (Connection conn = jdbcTemplate.getDataSource().getConnection();
             Statement stmt = conn.createStatement()) {

            // 1. Check if constraint already exists
            String tableName = "DIALENT";
            String constraintName = "ENT_FK";
            boolean exists = constraintExists(tableName, constraintName);

            // 2. Add to batch if not present
            if (!exists) {
                stmt.addBatch("""
                    ALTER TABLE dial.DIALENT
                    ADD CONSTRAINT ENT_FK
                    FOREIGN KEY (ENTDID)
                    REFERENCES dial.coredial(CORESID)
                    """);
                System.out.println("Added ENT_FK to batch.");
            } else {
                System.out.println("ENT_FK already exists. Skipping.");
            }

            // 3. Add more SQL to batch if needed
            // stmt.addBatch(...);

            // 4. Execute the batch
            stmt.executeBatch();
            System.out.println("Batch executed.");

        }
    }

    private boolean constraintExists(String tableName, String constraintName) {
        String sql = """
            SELECT COUNT(*) FROM user_constraints
            WHERE table_name = ? AND constraint_name = ?
        """;
        Integer count = jdbcTemplate.queryForObject(
            sql, Integer.class,
            tableName.toUpperCase(), constraintName.toUpperCase()
        );
        return count != null && count > 0;
    }
}

















